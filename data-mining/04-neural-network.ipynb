{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I wanted to understand about how neural networks work for the upcoming data mining exam (in the next 8 hours).\n",
    "I think the best way to understand neural networks is to build one.\n",
    "\n",
    "This notebook is based on:\n",
    "\n",
    "- The lecture slides on neural networks from Data Mining course, from textbook _Data Mining for Business Intelligence_ (Shmueli, Patel & Bruce).\n",
    "- The lecture slides on neural networks from Machine Learning course, from textbook _Machine Learning_ (T. Mitchell, McGraw Hill, 1997)\n",
    "- The homework worksheet from Data Mining course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Network\n",
    "\n",
    "So, __neural network__ is a network formed of neurons connected into a network of layers.\n",
    "A neuron has input and outputs. There are weights associated to each connection. So let's first construct a neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, value=None):\n",
    "        self.value = value\n",
    "        self.inputs = []\n",
    "        self.outputs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A connection class is used to hold the weights between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Connection:\n",
    "    def __init__(self, weight):\n",
    "        self.weight = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct our network based on the exercise sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fat    = Neuron()\n",
    "salt   = Neuron()\n",
    "output = Neuron()\n",
    "\n",
    "layers = [\n",
    "    [fat, salt],\n",
    "    [Neuron(), Neuron(), Neuron()],\n",
    "    [output],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `connect()` function connects between two neurons. The `connect_layer()` function connects between two layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def connect(a, b, weight):\n",
    "    conn = Connection(weight)\n",
    "    a.outputs.append((b, conn))\n",
    "    b.inputs.append((a, conn))\n",
    "\n",
    "def connect_layer(a, b, weights):\n",
    "    for j in range(len(b)):\n",
    "        connect(Neuron(1.0), b[j], weights[j][0])\n",
    "        for i in range(len(a)):\n",
    "            connect(a[i], b[j], weights[j][i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's connect the input layer to the hidden layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_layer(layers[0], layers[1], [\n",
    "    [-0.2, 0.02, 0.03],\n",
    "    [0.3, 0.01, -0.01],\n",
    "    [0.1, -0.01, 0.01],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then on to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connect_layer(layers[1], layers[2], [\n",
    "    [0.015, 0.015, 0.03, 0.01],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's put in the first input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fat.value = 0.2\n",
    "salt.value = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the value of a non-input neuron, we first take the weighted sum of each inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_sum(inputs):\n",
    "    return sum(input.value * connection.weight\n",
    "        for (input, connection) in inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_sum(layers[1][0].inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass it through a \"logistics\" function $g(s)$.\n",
    "For neural network, it is common to use a _sigmoid_ function $\\sigma$, which is defined as:\n",
    "\n",
    "$$ g(s) = \\sigma(s) = \\frac{1}{1 + e^{-s}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g(s):\n",
    "    return 1 / (1 + math.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4578502721432993"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g(weighted_sum(layers[1][0].inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here's how to compute the value of a neuron with inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute(neuron):\n",
    "    neuron.value = g(weighted_sum(neuron.inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the neuron from the hidden layer into the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation():\n",
    "    for i in range(1, len(layers)):\n",
    "        for neuron in layers[i]:\n",
    "            compute(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward_propagation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our network looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200, 0.900\n",
      "0.458, 0.573, 0.527\n",
      "0.511\n"
     ]
    }
   ],
   "source": [
    "def print_network():\n",
    "    for layer in layers:\n",
    "        print ', '.join('%.3f' % neuron.value for neuron in layer)\n",
    "\n",
    "print_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation\n",
    "\n",
    "The network says \"0.511\", we call that \"output\" ($o$). The actual \"target\" ($t$) result is \"1\", so we need to adjust the weights so that the network perform better.\n",
    "First, we calculate the error terms, then we update the weight based on these error terms.\n",
    "\n",
    "Note that these error terms are only valid for sigmoid units!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error term for output neuron\n",
    "\n",
    "$$ \\delta = o(1-o)(t-o) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1221706509801848"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_output(neuron, target):\n",
    "    output = neuron.value\n",
    "    return output * (1 - output) * (target - output)\n",
    "\n",
    "error_output(output, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary holding the error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_terms = { }\n",
    "error_terms[id(output)] = error_output(output, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error term for hidden neuron\n",
    "\n",
    "$$ \\delta = o(1-o)\\sum_{k \\in \\text{outputs}}{w_k\\delta_k} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003045540855178085"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_hidden(neuron, error_terms):\n",
    "    output = neuron.value\n",
    "    return (output * (1 - output) *\n",
    "        sum(connection.weight * error_terms[id(node)]\n",
    "            for (node, connection) in neuron.outputs))\n",
    "\n",
    "error_hidden(layers[1][-1], error_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: calculating the error terms\n",
    "\n",
    "We go backwards from output layer and calculate the error term for each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_error_terms(expected_outputs):\n",
    "    error_terms = {}\n",
    "    output_neurons = layers[-1]\n",
    "    for i in range(len(output_neurons)):\n",
    "        neuron = output_neurons[i]\n",
    "        error_terms[id(neuron)] = error_output(neuron, expected_outputs[i])\n",
    "    for k in range(-2, -len(layers), -1):\n",
    "        for neuron in layers[k]:\n",
    "            error_terms[id(neuron)] = error_hidden(neuron, error_terms)\n",
    "    return error_terms\n",
    "\n",
    "error_terms = calculate_error_terms([1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200, 0.900\n",
      "0.458(0.000455), 0.573(0.000897), 0.527(0.000305)\n",
      "0.511(0.122171)\n"
     ]
    }
   ],
   "source": [
    "def print_network_with_errors(error_terms):\n",
    "    def neuron_repr(neuron):\n",
    "        weight = '%.3f' % neuron.value\n",
    "        error_term = error_terms.get(id(neuron))\n",
    "        if error_term:\n",
    "            return weight + '(%f)' % error_term\n",
    "        else:\n",
    "            return weight\n",
    "    for layer in layers:\n",
    "        print ', '.join(neuron_repr(neuron) for neuron in layer)\n",
    "\n",
    "print_network_with_errors(error_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting weight\n",
    "\n",
    "$$ \\Delta w_{i, j} = \\eta \\delta_j x_i  $$\n",
    "\n",
    "There is a variable $\\eta$ representing the learning rate. This is usually a small number like 0.1. But for our purpose we'll learn very quickly with $\\eta = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "\n",
    "def adjust_weight(neuron, error_terms):\n",
    "    if id(neuron) not in error_terms: return\n",
    "    error = error_terms[id(neuron)]\n",
    "    for (input, connection) in neuron.inputs:\n",
    "        connection.weight += learning_rate * error * input.value\n",
    "\n",
    "def adjust_weights(error_terms):\n",
    "    for layer in layers:\n",
    "        for neuron in layer:\n",
    "            adjust_weight(neuron, error_terms)\n",
    "\n",
    "adjust_weights(error_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the new weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200[], 0.900[]\n",
      "0.458[-0.200,0.020,0.030], 0.573[0.300,0.010,-0.010], 0.527[0.100,-0.010,0.010]\n",
      "0.511[0.076,0.043,0.065,0.042]\n"
     ]
    }
   ],
   "source": [
    "def print_network_with_weights():\n",
    "    def neuron_repr(neuron):\n",
    "        return '%.3f[%s]' % (\n",
    "            neuron.value,\n",
    "            ','.join('%.3f' % connection.weight\n",
    "                         for (_, connection) in neuron.inputs))\n",
    "    for layer in layers:\n",
    "        print ', '.join(neuron_repr(neuron) for neuron in layer)\n",
    "\n",
    "print_network_with_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also perform forward propagation one more time to see the updated output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387254506541997"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_propagation()\n",
    "output.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output changed from $0.51$ to $0.53$, gradually learning the pattern.\n",
    "\n",
    "## Recap\n",
    "\n",
    "To recap, here's the backpropagation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backpropagation(expected_outputs):\n",
    "    error_terms = calculate_error_terms(expected_outputs)\n",
    "    adjust_weights(error_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100[], 0.100[]\n",
      "0.451[-0.200,0.020,0.030], 0.575[0.299,0.010,-0.010], 0.525[0.099,-0.010,0.010]\n",
      "0.539[0.009,0.013,0.027,0.007]\n"
     ]
    }
   ],
   "source": [
    "def train(fat_score, salt_score, acceptance):\n",
    "    fat.value = fat_score\n",
    "    salt.value = salt_score\n",
    "    forward_propagation()\n",
    "    backpropagation([acceptance])\n",
    "\n",
    "train(0.1, 0.1, 0.0)\n",
    "print_network_with_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200[], 0.400[]\n",
      "0.454[-0.201,0.020,0.030], 0.574[0.299,0.010,-0.010], 0.525[0.099,-0.010,0.010]\n",
      "0.508[-0.054,-0.016,-0.010,-0.026]\n"
     ]
    }
   ],
   "source": [
    "train(0.2, 0.4, 0.0)\n",
    "print_network_with_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stay hungry stay foolish\n",
    "\n",
    "Let's train it even more, like 2000 times. But not too much lest the neural network overfits.\n",
    "\n",
    "__Note__: We are using _case updating_, where we update the weights after each input data.\n",
    "There is also _batch updating_ where error terms are first aggregated before updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200[], 0.400[]\n",
      "0.390[0.612,0.060,-2.679], 0.673[2.739,0.271,-5.171], 0.619[2.252,0.214,-4.518]\n",
      "0.044[4.673,-2.449,-5.671,-4.809]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    train(0.2, 0.9, 1.0)\n",
    "    train(0.1, 0.1, 0.0)\n",
    "    train(0.2, 0.4, 0.0)\n",
    "\n",
    "print_network_with_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Let's see how well the network works now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def acceptance(fat_score, salt_score):\n",
    "    fat.value = fat_score\n",
    "    salt.value = salt_score\n",
    "    forward_propagation()\n",
    "    return output.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.945776394993\n",
      "0.00239254370444\n",
      "0.043855782356\n"
     ]
    }
   ],
   "source": [
    "print acceptance(0.2, 0.9)\n",
    "print acceptance(0.1, 0.1)\n",
    "print acceptance(0.2, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, after we trained the model several thousand times, the value becomes very close to what we expected. We can use thresholding to turn this into True/False value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
